<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Milestone 8 Progress Report &mdash; PACMANS  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Milestone 9 Progress Report" href="milestone9_report.html" />
    <link rel="prev" title="Milestone 7 Progress Report" href="milestone7_report.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> PACMANS
            <img src="_static/pacman_logo_v1.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="summary.html">Project Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone1_report.html">Milestone 1 Progress Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone2_report.html">Milestone 2 Progress Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone3_report.html">Milestone 3 Progress Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone4_report.html">Milestone 4 Progress Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone5_report.html">Milestone 5 Progress Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone6_report.html">Milestone 6 Progress Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone7_report.html">Milestone 7 Progress Report</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Milestone 8 Progress Report</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">1   Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#final-report-accomplishments">2   Final Report Accomplishments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">3 Final Report Accomplishments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#task-1-4-use-case-ocean-models-comparisons">4 Task 1.4 Use Case Ocean Models Comparisons</a></li>
<li class="toctree-l2"><a class="reference internal" href="#task-2-5-phase-1-data-final-delivery">5   Task 2.5: Phase 1 Data Final Delivery</a></li>
<li class="toctree-l2"><a class="reference internal" href="#task-3-6-ai-physics-informed-surrogate-model-phase-1-final-report">6   Task 3.6: AI Physics-Informed Surrogate Model Phase 1 Final Report</a></li>
<li class="toctree-l2"><a class="reference internal" href="#task-4-6-ai-simulation-phase-1-final-report">8    Task 4.6 AI Simulation Phase 1 Final Report</a></li>
<li class="toctree-l2"><a class="reference internal" href="#task-5-2-evaluation-final-report">7   Task 5.2: Evaluation Final Report</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="milestone9_report.html">Milestone 9 Progress Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone10_report.html">Milestone 10 Progress Report</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyBAMOCS:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="pyBAMOCS_intro.html">Introduction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Help &amp; Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="people.html">Our Team</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PACMANS</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Milestone 8 Progress Report</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/milestone8_report.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<a class="reference internal image-reference" href="_images/image1.png"><img alt="_images/image1.png" src="_images/image1.png" style="width: 9.40278in; height: 6.27303in;" /></a>
<section id="milestone-8-progress-report">
<h1>Milestone 8 Progress Report<a class="headerlink" href="#milestone-8-progress-report" title="Permalink to this heading">ïƒ</a></h1>
<p><strong>Approved for public release; distribution is unlimited. This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Agreement No. HR00112290032.</strong></p>
<p><strong>PACMANS TEAM:</strong>
â€¢ Jennifer Sleeman (JHU APL) PI
â€¢ Anand Gnanadesikan (JHU) Co-PI
â€¢ Yannis Kevrekidis (JHU) Co-PI
â€¢ Jay Brett (JHU APL)
â€¢ David Chung (JHU APL)
â€¢ Chace Ashcraft (JHU APL)
â€¢ Thomas Haine (JHU)
â€¢ Marie-Aude Pradal (JHU)
â€¢ Renske Gelderloos (JHU)
â€¢ Caroline Tang (DUKE)
â€¢ Anshu Saksena (JHU APL)
â€¢ Larry White (JHU APL)
â€¢ Marisa Hughes (JHU APL)</p>
<section id="overview">
<h2>1   Overview<a class="headerlink" href="#overview" title="Permalink to this heading">ïƒ</a></h2>
<blockquote>
<div><ul class="simple">
<li><p>This technical report covers the period of October 14, 2022, through December 12, 2022</p></li>
<li><p>The report documents the achievement of the milestone associated with Month 12 of the JHU/APL-led PACMAN teamâ€™s statement of work</p></li>
<li><p>The delivery for this milestone is this final report for Phase 1</p></li>
</ul>
</div></blockquote>
<p><a href="#id1"><span class="problematic" id="id2">**</span></a>Goals **
The goal for this milestone included:</p>
<blockquote>
<div><ul class="simple">
<li><p>Deliver final report of all modules to conclude the Phase 1 effort including: â€¢ Data analysis</p></li>
<li><p>Characterization of benefits of new hybrid models over conventional models</p></li>
<li><p>Evaluations</p></li>
<li><p>All models, source code, and datasets to support results</p></li>
</ul>
</div></blockquote>
</section>
<section id="final-report-accomplishments">
<h2>2   Final Report Accomplishments<a class="headerlink" href="#final-report-accomplishments" title="Permalink to this heading">ïƒ</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt>Development of the new 6-box model for AMOC tipping point research</dt><dd><ul>
<li><p>Enables the study of oscillations providing insights into why some slow-downs lead to full collapses whereas some lead to recovery, which could inform climate intervention strategies</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Generation of novel AMOC tipping point datasets geared toward machine learning</dt><dd><ul>
<li><p>Includes open sourced models being used by other performers</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>CEMS2 4-box model Verification â€“ Path for AI Learning of Large GCM Models</dt><dd><ul>
<li><p>Research showed 4-box model captures 60-90% of the variation in the AMOC and pycnocline of CESM2, suggesting 4-box results can be used to understand CMIP-class AMOC model disagreement</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>New bifurcation method for stochastic differential equations to estimate escape times in addition to identifying bifurcations</dt><dd><ul>
<li><p>Goes beyond state of the art in providing measurements for determining distance from a tipping point and likelihood of recovering â€“ applied to the stochastic 4-box model</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>New AI-based method: TIP-GAN, a generative adversarial network that is used to discover AMOC tipping points</dt><dd><ul>
<li><p>Generalizable to other types of tipping points</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Newly developed neuro-symbolic deep learning architecture that provides a means to ask questions of what is learned by TIP-GAN and a way to explore causal paths</p></li>
<li><p>First version of causal models based on TIP-GAN learned paths</p></li>
<li><p>Three accepted AGU presentations (2 oral, 1 poster), one AAAI Fall Symposium paper acceptance, draft of two journal papers, proposal acceptance to the AAAI Spring Symposium for AI Climate Tipping-Point Discovery (ACTD)</p></li>
</ul>
</section>
<section id="id3">
<h2>3 Final Report Accomplishments<a class="headerlink" href="#id3" title="Permalink to this heading">ïƒ</a></h2>
<p>This report includes a detailed final report for Phase 1 of:</p>
<ul class="simple">
<li><p>The conventional use of ocean models in terms of climate forecasting</p></li>
<li><p>Updates and delivery of any new datasets</p></li>
<li><p>Surrogate models performance with a comparison to conventional models using metrics defined in Milestone 3</p></li>
<li><p>Performance of the simulation, causal model, and neuro-symbolic translation, including a comparison with conventional models using metrics defined in Milestone 3</p></li>
<li><p>Benchmark comparison between the AI approach and the conventional approach, comparing their performance</p></li>
</ul>
</section>
<section id="task-1-4-use-case-ocean-models-comparisons">
<h2>4 Task 1.4 Use Case Ocean Models Comparisons<a class="headerlink" href="#task-1-4-use-case-ocean-models-comparisons" title="Permalink to this heading">ïƒ</a></h2>
<p><em>Subtask Description: We will provide a final report detailing the conventional use of ocean models in terms of climate forecastig</em></p>
<p>In this report we provide a detailed discussion around the 4-box and 6-box models and the benefits of using these models to train machine learning algorithms with a path towards applying machine learning algorithms to large coupled GCMs.</p>
<p><strong>Task 1.4: Use Case Ocean Models Comparisons â€“ 4-Box Model</strong>
On long time scales, Atlantic overturning can often be described by the simple box modelâ€¦
â€¦ which exhibits tipping points.</p>
<ul>
<li><p>We used the box model as a first-step data set</p></li>
<li><p>We then extended this to include the larger climate models</p>
<blockquote>
<div><ul class="simple">
<li><p>Extend to include Pacific Basin</p></li>
<li><p>Calibrated model against specific climate models (NCAR+CMIP6) using preindustrial and historical simulations</p></li>
<li><p>Showed that model can capture both mean state and variability</p></li>
<li><p>Used surrogate model to project tipping points, examine for accuracy of prediction</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p><a class="reference internal" href="_images/image217.png"><img alt="image1" src="_images/image217.png" style="width: 3.82222in; height: 5.175in;" /></a></p>
<blockquote>
<div><div class="line-block">
<div class="line"><em>Gnanadesikan, 1999;</em></div>
<div class="line"><em>Gnanadesikan, Kelson and Sten, J. Climate 2018</em></div>
</div>
</div></blockquote>
<p>** Task 1.4: Use Case Ocean Models Comparisons â€“ 6-Box Model**</p>
<a class="reference internal image-reference" href="_images/image208.png"><img alt="_images/image208.png" src="_images/image208.png" style="width: 6in; height: 4in;" /></a>
<ul class="simple">
<li><dl class="simple">
<dt>In the calibrating model, Pacific shows more â€œresistanceâ€ to overturning than Southern Ocean. Why?</dt><dd><ul>
<li><p>Atlantic is denser than Southern Ocean</p></li>
<li><p>Sinking gets kick from both intermediate and shallow water (low resistance)</p></li>
<li><p>Pacific is lighter than Southern Ocean. Sinking is opposed by AAIWâ€¦ (higher resistance)</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>North Pacific receives less freshwater than North Atlantic +Arctic</p></li>
</ul>
<a class="reference internal image-reference" href="_images/image513.png"><img alt="_images/image513.png" src="_images/image513.png" style="width: 4in; height: 2in;" /></a>
<a class="reference internal image-reference" href="_images/image612.png"><img alt="_images/image612.png" src="_images/image612.png" style="width: 4in; height: 2in;" /></a>
<p>If freshwater flux is higher in the Pacific, increasing hydrological cycle shuts off Pacific first, then Atlantic.</p>
<p>If freshwater flux is higher in Atlantic/Arctic, potential for restart of Pacific overturning when Arctic turns off.</p>
<p>Three ways of increasing Pacific overturning!</p>
<a class="reference internal image-reference" href="_images/image712.png"><img alt="_images/image712.png" src="_images/image712.png" style="width: 6in; height: 5in;" /></a>
<p>When Atlantic overturning shuts off, pycnocline deepens.
This increases the mixing between high and low latitudesâ€¦ more in Pacific than Atlantic.
For realistic range of mixing fluxes this can lead to restart of strong intermediate water formation in Pacific.</p>
<a class="reference internal image-reference" href="_images/image812.png"><img alt="_images/image812.png" src="_images/image812.png" style="width: 4in; height: 6in;" /></a>
</section>
<section id="task-2-5-phase-1-data-final-delivery">
<h2>5   Task 2.5: Phase 1 Data Final Delivery<a class="headerlink" href="#task-2-5-phase-1-data-final-delivery" title="Permalink to this heading">ïƒ</a></h2>
<p><em>Subtask Description: We will document updates and deliver any new datasets.</em></p>
<p>The final delivery of data will include the following:</p>
<ul class="simple">
<li><p>4-box Model Python machine learning generated datasets</p></li>
<li><p>Stochastic 4-box Model Python machine learning generated datasets</p></li>
<li><p>6-box Model Matlab code on github, but the machine learning generated datasets are not finalized yet</p></li>
<li><p>Calibrated 4-box Model CESM2 Large Ensemble datasets</p></li>
</ul>
<p><a href="#id4"><span class="problematic" id="id5">**</span></a>Task 2.5: Phase 1 Data Final Delivery â€“ 4-Box Model **</p>
<ul>
<li><p>Using the 4-box model as a way to generate data for the AI methods</p></li>
<li><p>For long time scales, Atlantic overturning can often be described by the simple box model</p>
<blockquote>
<div><a class="reference internal image-reference" href="_images/image912.png"><img alt="_images/image912.png" src="_images/image912.png" style="width: 7.80278in; height: 3.72917in;" /></a>
</div></blockquote>
</li>
</ul>
<p>The Gnanadesikan 4-Box Model</p>
<ul>
<li><p>Created a python package of the 4-box model that allows one to specify initial conditions, and parameter values</p></li>
<li><p>The python package recreates the Gnanadesikan experiments (in Matlab code)</p></li>
<li><p>Generates the same plots</p></li>
<li><p>Enables creation of labeled training data for training machine learning algorithms and temporal training data for training the AI surrogates</p></li>
<li><p>Produces datasets in netcdf format</p>
<blockquote>
<div><a class="reference internal image-reference" href="_images/image1010.png"><img alt="_images/image1010.png" src="_images/image1010.png" style="width: 4.80278in; height: 2.72917in;" /></a>
<a class="reference internal image-reference" href="_images/image116.png"><img alt="_images/image116.png" src="_images/image116.png" style="width: 3.80278in; height: 2.72917in;" /></a>
</div></blockquote>
</li>
</ul>
<ul class="simple">
<li><p>Data available on sciserver.org</p></li>
<li><p>Code available at <a class="reference external" href="https://github.com/JHUAPL/PACMANs">https://github.com/JHUAPL/PACMANs</a></p></li>
<li><p>4-box model tutorial is on the ACTM Gallery</p></li>
</ul>
<a class="reference internal image-reference" href="_images/image126.png"><img alt="_images/image126.png" src="_images/image126.png" style="width: 3.80278in; height: 1.72917in;" /></a>
<a class="reference internal image-reference" href="_images/image145.png"><img alt="_images/image145.png" src="_images/image145.png" style="width: 3.80278in; height: 2.72917in;" /></a>
<a class="reference internal image-reference" href="_images/image155.png"><img alt="_images/image155.png" src="_images/image155.png" style="width: 3.80278in; height: 2.72917in;" /></a>
<p>** Task 2.5: Phase 1 Data Final Delivery â€“ 6-Box Model**</p>
<ul class="simple">
<li><p>6-box model Matlab code is in github</p></li>
<li><p>Python code for the 6-box model has been developed</p></li>
<li><p>Scripts to generate Machine Learning datasets are also built</p></li>
<li><dl class="simple">
<dt>However, the code requires formal review, documentation and tutorials before release in github public</dt><dd><p>â€’ Will be part of Phase2</p>
</dd>
</dl>
</li>
</ul>
<a class="reference internal image-reference" href="_images/image522.png"><img alt="_images/image522.png" src="_images/image522.png" style="width: 5.80278in; height: 2.72917in;" /></a>
<p><strong>Task 2.5: Phase 1 Data Final Delivery â€“ CESM2</strong></p>
<p>Fitting CESM2 Large Ensemble to the Gnanadesikan 4-box model</p>
<a class="reference internal image-reference" href="_images/image209.png"><img alt="_images/image209.png" src="_images/image209.png" style="width: 6.80278in; height: 4.72917in;" /></a>
<p><strong>Goodness of fit</strong></p>
<p>For each of the 11 ensemble members, the correlation coefficient and the rms error normalized by the mean are shown for both the AMOC (Mn) and the pycnocline depth (D). Recall that member 1 is used to fit the data- it is excluded from the following:</p>
<p>The mean correlation coefficient is 0.9 for Mn and 0.8 for D.</p>
<p>On average, the rms error is 12% of the mean Mn and 1% of the mean D.</p>
<a class="reference internal image-reference" href="_images/image951.png"><img alt="_images/image951.png" src="_images/image951.png" style="width: 4.04583in; height: 3.06944in;" /></a>
</section>
<section id="task-3-6-ai-physics-informed-surrogate-model-phase-1-final-report">
<h2>6   Task 3.6: AI Physics-Informed Surrogate Model Phase 1 Final Report<a class="headerlink" href="#task-3-6-ai-physics-informed-surrogate-model-phase-1-final-report" title="Permalink to this heading">ïƒ</a></h2>
<blockquote>
<div><p><em>Subtask Description: We will provide a final report of the surrogate models performance with a comparison to conventional models using metrics defined in Milestone 3.</em></p>
</div></blockquote>
<p>In this report we review the findings of the bifurcation analysis and provide a comparative estimate of the time required to compute the Escape Time Distribution with the Full Model and the Learned Parameter Dependent effective Stochastic Differential Equation target tipping point surrogate model.</p>
<p><strong>Task 3.6: AI Physics-Informed Surrogate Model Phase 1 Final Report â€“ Bifurcation Analysis</strong></p>
<a class="reference internal image-reference" href="_images/image981.png"><img alt="_images/image981.png" src="_images/image981.png" style="width: 5.62in; height: 3.59in;" /></a>
<dl class="simple">
<dt>We consider a dynamical box model with four boxes:</dt><dd><ul class="simple">
<li><p>The southern high latitudes (0.308S)</p></li>
<li><p>The northern high latitudes (0.458N)</p></li>
<li><p>Mid-to-low latitudes</p></li>
<li><p>A deep box that lies beneath all of the surface boxes</p></li>
</ul>
</dd>
</dl>
<p>State variables:</p>
<blockquote>
<div><ul class="simple">
<li><p>ğ·: Low latitude pycnocline depth</p></li>
<li><p>T_S,T_n,T_l, T_d: Temperatures of the four boxes</p></li>
<li><p>S_S,S_n,S_l, S_d: Salinities of the four boxes â€¢</p></li>
<li><p>Single-headed bold arrows denote net fluxes of water</p></li>
<li><p>Double-headed arrows denote mixing fluxes</p></li>
</ul>
</div></blockquote>
<p><a href="#id8"><span class="problematic" id="id9">|image211|</span></a>
These are the equations that we start with (nine differential equations)</p>
<p><a href="#id10"><span class="problematic" id="id11">|image212|</span></a></p>
<p>IMPORTANTLY, we explicitly used the fact that there exists an algebraic constraint (a salt balance) that reduces the equations by one and removes a neutral direction. This helps the conditioning of the Jacobian</p>
<p><a href="#id12"><span class="problematic" id="id13">|image213|</span></a></p>
<p>To make computations more accurate numerically, we non-dimensionalized the equations in ways <em>meaningful to the domain scientist</em> (Anand G.) to reduce the number of free parameters</p>
<p>With the non-dimensionalized equations, the problem possesses not one, but two tipping points (from the â€œupperâ€ branch to the lower, but also from the lower to the upper) as shown in figures below.</p>
<a class="reference internal image-reference" href="_images/image1341.png"><img alt="_images/image1341.png" src="_images/image1341.png" style="width: 5.04583in; height: 3.06944in;" /></a>
<p>Diagram of NH Overturning Mn</p>
<a class="reference internal image-reference" href="_images/image135.png"><img alt="_images/image135.png" src="_images/image135.png" style="width: 5.04583in; height: 3.06944in;" /></a>
<p>Zoomed-In View of the subcritical Hopf Bifurcation Point</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Second view - the two tipping points are of different nature: one
of the two is the fold point bifurcation, but the second one is a
subcritical Hopf, highlighted in below figures. The Hopf at
TrFWn=0.0384 is subcritical.</p>
<p><a class="reference internal" href="_images/image136.png"><img alt="image122" src="_images/image136.png" style="width: 5.07639in; height: 3.87083in;" /></a> <a class="reference internal" href="_images/image137.png"><img alt="image123" src="_images/image137.png" style="width: 5.07639in; height: 3.87083in;" /></a></p>
</th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td></td>
</tr>
</tbody>
</table>
<p>Diagram of Low Latitude Depth D* (left) and Zoomed-In View of the Hopf Bifurcation Point (right).</p>
<p>The Hysteretic behavior found in [Gnanadesikan, Kelson, Sten 2018], can be described as:</p>
<blockquote>
<div><ul class="simple">
<li><p>The â€˜switchingâ€™ between â€˜offâ€™ and â€˜onâ€™ state is given by a subcritical Hopf bifurcation: H for ğ‘‡ğ‘Ÿ&#64; = 0.03529</p></li>
<li><p>And a saddle-node bifurcation: LP for ğ‘‡ğ‘Ÿ&#64; = 0.01798 TU</p></li>
</ul>
</div></blockquote>
<p><img alt="image138" src="_images/image1551.png" /></p>
<ul class="simple">
<li><p>The value where the limit cycle branch appears to become vertical (an infinite period, homoclinic orbit) is 0.0375</p></li>
<li><p>The subcritical Hopf gives birth to an unstable limit cycle â€œbackwardsâ€ in parameter space (that surrounds the exiting stable steady state)</p></li>
<li><p>This steady state loses stability at the Hopf bifurcation (red branch in figures)</p></li>
<li><p>The escape (the â€œtippingâ€) arises when a stochastic trajectory wandering around the stable state manages to â€œcrossâ€ the unstable limit cycle and escape to either large oscillations or to a completely different lower circulation branch</p></li>
</ul>
<p>Where the initial condition with D=1 (where D is the low latitude pycnocline depth) is attracted by the upper branch because there is an early switch activation, so the sharp transition that we see is given by the upper limit point (LP). While for D=4 we observe the sharp transition close to the subcritical Hopf (the solution loses stability at the exact Hopf point because the initial condition may start outside the unstable limit cycle).</p>
<blockquote>
<div><p><a class="reference internal" href="_images/image140.png"><img alt="image126" src="_images/image140.png" style="width: 5.08056in; height: 3.80972in;" /></a> <a class="reference internal" href="_images/image1411.png"><img alt="image127" src="_images/image1411.png" style="width: 5.08055in; height: 3.80972in;" /></a></p>
</div></blockquote>
<p>Temporal Bifurcation Diagram for Depth (top) and the Limit Cycle Continuation (bottom)</p>
<p><strong>Task 3.6: AI Physics-Informed Surrogate Model Phase 1 Final Report â€“ Stochastic Model</strong></p>
<ul class="simple">
<li><p>Sitting close to the subcritical Hopf tipping point, on its â€œsafe sideâ€ we performed our first stochastic simulations (with fluctuating freshwater flux coefficient, again, designed in collaboration with the domain expert, Anand G.)</p></li>
<li><p>Notice on the left simulations, the variable oscillates over time near 4.7 before it eventually â€œtipsâ€</p></li>
<li><p>Also notice on the right some initial statistics of escape times for a fixed parameter value</p></li>
</ul>
<p><a href="#id14"><span class="problematic" id="id15">|image215|</span></a></p>
<p>The Stochastic Differential Equation (SDE) model was trained by using sampled data of the Full Networkâ€™s Dynamics. Those data were used to train a parameter dependent SDE network (for two values of the parameter p).</p>
<p>For the neural networkâ€™s training we used snapshots of the Full Model every five iterations of the full model assuming a time step h=0.01.</p>
<p>To estimate the computational time needed per approach, we first obtain an evaluation of the time needed for a function evaluation of the Full Model and of the estimated SDE (eSDE) model:
+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”-+
|              <strong>Function Evaluation Time (seconds)</strong>                   |
+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”-+
|            Full Model              |            eSDE Model            |
+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”-+
|             0.0529                 |            0.00188               |
+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”-+</p>
<p>To obtain an estimate of the number of trajectories needed for each model to compute the escape time distribution, a bootstrapping method was used for each model.</p>
<p>For both models, the number of samples needed was estimated to be N=2000.</p>
<p>Given this information, we then estimate the number of iterations (evaluations) needed for each model, on average, to escape.</p>
<p>For the Full Model, this number was estimated as 281.</p>
<p>For the Reduced Model, since the escape time was estimated as 0.289 (for a time step of the Euler Maryama simulation equal to the one assumed when training of the model (h=0.01)), we estimate that the number of iterations is 28.9 ~29.</p>
<p>By considering the Function Evaluation time for each model, the number of samples needed to obtain an accurate estimate of the escape times, but also the number of iterations per model, we obtain an estimate of the computational time required to compute the exit time distribution per model.
+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“+
| | <strong>Escape Time Computational  |  |                                   |
| | Effort (hours)</strong>             |  |                                   |
+===================================+===================================+
| +â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”+  | <strong>eSDE Model</strong>                    |
| | <strong>Full Model</strong>               |  |                                   |
| +â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”+  |                                   |
+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“+
| +â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”+  | 0.00301                           |
| | 8.26                         |  |                                   |
| +â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”+  |                                   |
+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“+â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“+</p>
<blockquote>
<div><p>The computational efforts were estimated for the Full Model as
follows:</p>
</div></blockquote>
<dl class="simple">
<dt>The computational efforts were estimated for the Full Model as follows:</dt><dd><ul class="simple">
<li><p>Escape Time Computational Effort =Average Number of Iterations Full Model * Number of Samples Needed <a href="#id6"><span class="problematic" id="id7">*</span></a>Function Evaluation Time</p></li>
</ul>
</dd>
<dt>The computations efforts for the SDE Model were obtained as follows:</dt><dd><ul class="simple">
<li><p>Escape Time Computational Effort = (Mean Exit Time obtained)/h* Number of Samples Needed*Function Evaluation Time</p></li>
</ul>
</dd>
</dl>
<p>Please notice that the function evaluation difference between the Full Model is ~28 times larger than the SDE model. However, the ratio of the computational time suggests that the Full Model need is ~273 times more than the SDE model. This can be attributed to the following two reasons:</p>
<ol class="arabic simple">
<li><p>We trained the SDE model by using every 5 iterations of the full model so each step of the reduced model corresponds to 5 steps of the Full Model</p></li>
<li><p>The escape time estimated of the full model is ~2 times larger than the SDE model</p></li>
</ol>
<p>Those two reasons make the computation of the exit time of the SDE model even smaller than the factor of 28.</p>
<p>Additional Computational Cost needed for these computations involve:</p>
<ol class="arabic simple">
<li><p>Sampling the data</p></li>
<li><p>Training the SDE Model</p></li>
</ol>
<p>In terms of (1) we sampled a total number of 104,000 data points to train the SDE (even though not all were used). By considering the function evaluation time of the Full Model, the time needed to sample the data was ~1.5 hours. Note that the real time might be larger since computing and storing in RAM those trajectories might increase the time required just for simulation.</p>
<p>The training of the SDE model (training for 1,000 epochs) needs about 0.23 hours. The table below reports the total computational time needed for the SDE model.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>Task</strong></p></td>
</tr>
</tbody>
</table>
</th>
<th class="head"><p><strong>Computational Time (hours)</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td></td>
<td></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Sampling Data</p></td>
</tr>
</tbody>
</table>
</th>
<th class="head"><p>1.5</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Training SDE Model</p></td>
</tr>
</tbody>
</table>
</td>
<td><p>0.23</p></td>
</tr>
<tr class="row-odd"><td><table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Escape Time Computations
SDE Model</p></td>
</tr>
</tbody>
</table>
</td>
<td><p>0.031</p></td>
</tr>
<tr class="row-even"><td><table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Total</p></td>
</tr>
</tbody>
</table>
</td>
<td><p>1.78</p></td>
</tr>
</tbody>
</table>
</section>
<section id="task-4-6-ai-simulation-phase-1-final-report">
<h2>8    Task 4.6 AI Simulation Phase 1 Final Report<a class="headerlink" href="#task-4-6-ai-simulation-phase-1-final-report" title="Permalink to this heading">ïƒ</a></h2>
<p><em>Subtask Description: We will provide a final report of the performance of the simulation, causal model, and neuro-symbolic translation, including a comparison with conventional models using metrics defined in Milestone 3.</em></p>
<p>In this final report we share the measured results for TIP-GAN, the neuro-symbolic translation methods, and early results from the causal model. Each area of experimentation was measured in terms of the metrics described previously and new metrics as required.</p>
<p><strong>Task 4.6: AI Simulation Phase 1 Final Report - TIP-GAN</strong>
Compelling early classification precision, recall, F1 scores of model configurations that lead to AMOC collapse in 4-box model</p>
<dl class="simple">
<dt>..image:: _static/media8/image143.png</dt><dd><dl class="field-list simple">
<dt class="field-odd">width</dt>
<dd class="field-odd"><p>5.018in</p>
</dd>
<dt class="field-even">height</dt>
<dd class="field-even"><p>3.763in</p>
</dd>
</dl>
</dd>
<dt>..image:: _static/media8/image144.png</dt><dd><dl class="field-list simple">
<dt class="field-odd">width</dt>
<dd class="field-odd"><p>5.018in</p>
</dd>
<dt class="field-even">height</dt>
<dd class="field-even"><p>3.763in</p>
</dd>
</dl>
</dd>
<dt>..image:: _static/media8/image145.png</dt><dd><dl class="field-list simple">
<dt class="field-odd">width</dt>
<dd class="field-odd"><p>5.018in</p>
</dd>
<dt class="field-even">height</dt>
<dd class="field-even"><p>3.763in</p>
</dd>
</dl>
</dd>
</dl>
<p>Recreated Collapses Using Python Generated Tools for Machine Learning Dataset Creation from the 4-Box Model</p>
<p>Learning Dataset Creation from the 4-Box Model</p>
<p>Showed that the GAN could be used to exploit the area of uncertainty connsistent with what was desvribed i the 2018 4-Box Model paper.</p>
<p>Training samples: 10,774
Test samples: 2,694
GAN samples: 2,694
N = number of generators</p>
<p>Dataset and Percent in uncertainty region:
Training: 34.9%
Test: 35.5%
GAN (N=1): 67.4%
GAN (N=2): 91.4%
GAN (N=3): 98.7%</p>
<a class="reference internal image-reference" href="_images/image148.png"><img alt="_images/image148.png" src="_images/image148.png" style="width: 4.37778in; height: 1.76667in;" /></a>
<a class="reference internal image-reference" href="_images/image146.png"><img alt="_images/image146.png" src="_images/image146.png" style="width: 4.37778in; height: 1.76667in;" /></a>
<a class="reference internal image-reference" href="_images/image147.png"><img alt="_images/image147.png" src="_images/image147.png" style="width: 4.37778in; height: 1.76667in;" /></a>
<p>Comparing GAN Generated Results for N = (1,2,3) with the Test Set.</p>
<ul class="simple">
<li><dl class="simple">
<dt>Next Steps:</dt><dd><ul>
<li><dl class="simple">
<dt>Perturb more variables</dt><dd><ul>
<li><p>Joint exploration (ğ´TU&lt;V, ğ´WX, ğ‘€UY, ğ¾Z, ğœ€, ğ·;[R, ğ¹:)</p></li>
<li><p>Time (N and tstep_size)</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><p>Additional label (e.g. AMOC recoveries)</p></li>
<li><p>Larger/stochastic surrogate models (e.g. 6-box model, stochastic 4-box model, AI surrogate model)</p></li>
</ul>
<a class="reference internal image-reference" href="_images/image1661.png"><img alt="_images/image1661.png" src="_images/image1661.png" style="width: 3.37778in; height: 3.76667in;" /></a>
<p><strong>Task 4.6: AI Simulation Phase 1 Final Report â€“ Neuro-Symbolic</strong></p>
<blockquote>
<div><a class="reference internal image-reference" href="_images/image1671.png"><img alt="_images/image1671.png" src="_images/image1671.png" style="width: 8.76111in; height: 4.94722in;" /></a>
</div></blockquote>
<p>Learning to Translate Questions into Programs and Programs into Questions</p>
<p>Using the CLEVR dataset to validate architectures: (<a class="reference external" href="https://cs.stanford.edu/people/jcjohns/clevr/">https://cs.stanford.edu/people/jcjohns/clevr/</a>)</p>
<ul class="simple">
<li><p>Common dataset for neuro-symbolic method evaluation</p></li>
<li><p>Specific to image object understanding</p></li>
<li><p>We adapt this dataset and use only the question and program portions of the data</p></li>
</ul>
<p>Task 4.6: AI Simulation Phase 1 Final Report - Neuro-Symbolic</p>
<ul class="simple">
<li><p>Used 59,307 training samples and 12,698 test samples</p></li>
<li><p>Trained network with shared word embeddings</p></li>
<li><p>Evaluated using test samples</p></li>
<li><p>Test samples contained both natural language questions and equivalent programs</p></li>
<li><p>~75% accuracy overall translating from questions to questions, questions to programs, and programs to questions</p></li>
</ul>
<p><strong>*Example Output:*</strong></p>
<p><strong>Predicted text:</strong> BOS how many small cyan things are there ? EOS</p>
<p><strong>Ground Truth Text:</strong> BOS how many small cyan things are there ? EOS</p>
<p><strong>Predicted program:</strong> BOS count ( filter_color ( filter_size ( scene , small ) , cyan ) ) EOS Ground Truth program: BOS count ( filter_color ( filter_size ( scene , small ) , cyan ) ) EOS Predicted text from program: BOS how many of cyan things are are ? ? EOS</p>
<ul>
<li><p>Validated using the CLEVR dataset</p></li>
<li><p>Translates GAN output into NL Questions</p></li>
<li><dl>
<dt>Able to convert NL Questions into symbolic Programs that the GAN could answer</dt><dd><a class="reference internal image-reference" href="_images/image169.png"><img alt="_images/image169.png" src="_images/image169.png" style="width: 4.76111in; height: 1.94722in;" /></a>
</dd>
</dl>
</li>
</ul>
<p>Example GAN Output Translated from Program to NL Question/Answer</p>
<blockquote>
<div><a class="reference internal image-reference" href="_images/image170.png"><img alt="_images/image170.png" src="_images/image170.png" style="width: 5.76111in; height: 3.94722in;" /></a>
</div></blockquote>
<p>Using 4-Box Model Dataset (Small experiment)</p>
<blockquote>
<div><a class="reference internal image-reference" href="_images/image1711.png"><img alt="_images/image1711.png" src="_images/image1711.png" style="width: 5.76111in; height: 3.94722in;" /></a>
</div></blockquote>
<p>Using CLEVR Dataset</p>
<blockquote>
<div><a class="reference internal image-reference" href="_images/image1721.png"><img alt="_images/image1721.png" src="_images/image1721.png" style="width: 5.76111in; height: 3.94722in;" /></a>
</div></blockquote>
<ul>
<li><dl class="simple">
<dt>Adding additional questions to the training dataset</dt><dd><ul class="simple">
<li><p>~250,000 generated questions</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Transfer from model trained purely on CLEVR data</p></li>
<li><p>40 token question max</p></li>
<li><p>Preliminary results</p>
<blockquote>
<div><ul class="simple">
<li><p>Overall Test Set accuracy: 83%</p></li>
<li><p>Test size: 25,000 question/program pairs</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>New (examples of) AMOC-Specific Questions:</p>
<ul class="simple">
<li><p>If I increase ekman flux by some value will overturning increase</p></li>
<li><p>If I increase low lat thermocline depth by some value will overturning increase</p></li>
<li><p>If I decrease freshwater flux by some value will overturning decrease</p></li>
<li><p>If I set ekman flux to some value, freshwater flux to some value and the thermocline depth of lower latitudes to some value will overturning increase..</p></li>
</ul>
<p><strong>Task 4.6: AI Simulation Phase 1 Final Report â€“ Causal Modeling</strong></p>
<ul>
<li><p>Causal path learning algorithmic development underway</p></li>
<li><p>For each epoch, each generator will have a set of batch models it perturbed</p></li>
<li><p>Causal model is built from batches perturbed over the total epoch for each generator</p></li>
<li><p>We focus on the 3-parameter experiments involving:</p>
<blockquote>
<div><ul class="simple">
<li><p>Dlow0 - Thermocline depth of lower latitudes</p></li>
<li><p>Mek - Ekman flux from the southern ocean</p></li>
<li><p>Fwn - Fresh water flux (North)</p></li>
</ul>
</div></blockquote>
</li>
<li><p>And on the relationship between freshwater, salinity, temperature with respect to overturning:</p>
<blockquote>
<div><ul class="simple">
<li><p>T_south â€“ Temperatures of the southern box</p></li>
<li><p>T_north â€“ Temperatures of the northern box</p></li>
<li><p>S_south â€“ Salinity of the southern box</p></li>
<li><p>S_north â€“ Salinity of the northern box</p></li>
<li><p>D_low0 â€“ Thermocline depth of lower latitudes</p></li>
<li><p>M_n â€“ Overturning Transport</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="task-5-2-evaluation-final-report">
<h2>7   Task 5.2: Evaluation Final Report<a class="headerlink" href="#task-5-2-evaluation-final-report" title="Permalink to this heading">ïƒ</a></h2>
<p><em>Subtask Description: We report on the results of a benchmark comparison between the AI approach and the conventional approach, comparing their performance.</em></p>
<p>We summarize the results of the benchmark comparison between the AI approach and the conventional approach.</p>
<ul class="simple">
<li><p>In the surrogate modeling bifurcation efforts, a Hopf bifurcation was detected for the 4-box model (in addition to previously known fold bifurcations)</p></li>
<li><p>In the TIP-GAN experiments, when benchmarking with the 4-box model, we showed that the TIP-GAN generators when focused on the area of uncertainty in terms of discriminator predictions was consistent with the area of the separatrix</p></li>
<li><p>In the neuro-symbolic translations we benchmarked the networkâ€™s performance in terms of a common benchmark â€“ the CLEVR dataset and performance was exceptional (close to 100%) for text-to-text translations and text-to-program translations using Levenshtein distance. Program to text was over 60% in terms of performance</p></li>
</ul>
<p><strong>Summary</strong>
Phase 1 source code can be found in github</p>
<p>Phase 1 datasets can be found at sciserver.com</p>
<p>Phase 1 reports can be found on readthedocs</p>
<a class="reference internal image-reference" href="_images/image126.png"><img alt="_images/image126.png" src="_images/image126.png" style="width: 4.53889in; height: 1.65972in;" /></a>
<p>1. Boers, Niklas. â€œObservation-based early-warning signals for a collapse of the Atlantic Meridional Overturning Circulation.â€ Nature Climate Change 11, no. 8
(2021): 680-688.
2. Gnanadesikan, A., A simple model for the structure of the oceanic pycnocline, Science., 283:2077-2079, (1999).
3. Forget, G., J.-M. Campin, P. Heimbach, C. N. Hill, R. M. Ponte, C. Wunsch, ECCO version 4: An integrated framework for non-linear inverse modeling and global ocean state estimation. Geosci. Model Dev. 8, 3071â€“3104 (2015)
4. Gnanadesikan, A., R. Kelson and M. Sten, Flux correction and overturning stability: Insights from a dynamical box model, J. Climate, 31, 9335-9350, <a class="reference external" href="https://doi.org/10.1175/JCLI-D-18-0388.1">https://doi.org/10.1175/JCLI-D-18-0388.1</a>, (2018).
5. Kaufhold, John Patrick, and Jennifer Alexander Sleeman. â€œSystems and methods for deep model translation generation.â€ U.S. Patent No. 10,504,004. 10 Dec. 2019.
6. Garcez, Artur dâ€™Avila, and Luis C. Lamb. â€œNeurosymbolic AI: the 3rd Wave.â€ arXiv preprint arXiv:2012.05876 (2020).
7. Stommel, H. Thermohaline convection with two stable regimes of flow. Tellus 13, 224â€“230 (1961).
8. Karniadakis, George Em, Ioannis G. Kevrekidis, Lu Lu, Paris Perdikaris, Sifan Wang, and Liu Yang. â€œPhysics-informed machine learning.â€ Nature Reviews Physics 3, no. 6 (2021): 422-440.
9. Sleeman, Jennifer, Milton Halem, Zhifeng Yang, Vanessa Caicedo, Belay Demoz, and Ruben Delgado. â€œA Deep Machine Learning Approach for LIDAR Based Boundary Layer Height Detection.â€ In IGARSS 2020-2020 IEEE International Geoscience and Remote Sensing Symposium, pp. 3676-3679. IEEE, 2020.
10. Patel, Kinjal, Jennifer Sleeman, and Milton Halem. â€œPhysics-aware deep edge detection network.â€ In Remote Sensing of Clouds and the Atmosphere XXVI, vol. 11859, pp. 32-38. SPIE, 2021.
11.BrulÃ©, Joshua. â€œA causation coefficient and taxonomy of correlation/causation relationships.â€ arXiv preprint arXiv:1708.05069 (2017).
12. Rasp, Stephan, Michael S. Pritchard, and Pierre Gentine. â€œDeep learning to represent subgrid processes in climate models.â€ Proceedings of the National Academy of Sciences 115, no. 39 (2018): 9684-9689.
13. Bolton, Thomas, and Laure Zanna. â€œApplications of deep learning to ocean data inference and subgrid parameterization.â€ Journal of Advances in Modeling Earth Systems 11, no. 1 (2019): 376-399.
14. Kurth, Thorsten, Sean Treichler, Joshua Romero, Mayur Mudigonda, Nathan Luehr, Everett Phillips, Ankur Mahesh et al. â€œExascale deep learning for climate analytics.â€ In SC18: International Conference for High Performance Computing, Networking, Storage and Analysis, pp. 649-660. IEEE, 2018.
15. Weber, Theodore, Austin Corotan, Brian Hutchinson, Ben Kravitz, and Robert Link. â€œDeep learning for creating surrogate models of precipitation in Earth system models.â€ Atmospheric Chemistry and Physics 20, no. 4 (2020): 2303-2317.
16. Matsubara, Takashi, Ai Ishikawa, and Takaharu Yaguchi. â€œDeep energy-based modeling of discrete-time physics.â€ arXiv preprint arXiv:1905.08604 (2019).
17. Kleinen, T., Held, H. &amp; Petschel-Held, G. The potential role of spectral properties in detecting thresholds in the Earth system: application to the thermohaline circulation. Ocean Dyn. 53, 53â€“63 (2003).
18. Kocaoglu, Murat, Christopher Snyder, Alexandros G. Dimakis, and Sriram Vishwanath. â€œCausalgan: Learning causal implicit generative models with adversarial training.â€ arXiv preprint arXiv:1709.02023 (2017).
19. Feinman, Reuben, and Brenden M. Lake. â€œLearning Task-General Representations with Generative Neuro-Symbolic Modeling.â€ arXiv preprint arXiv:2006.14448 (2020).
20. Yi, Kexin, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio Torralba, and Joshua B. Tenenbaum. â€œClevrer: Collision events for video representation and reasoning.â€ arXiv preprint arXiv:1910.01442 (2019).
21. Nowack, Peer, Jakob Runge, Veronika Eyring, and Joanna D. Haigh. â€œCausal networks for climate model evaluation and constrained projections.â€ Nature communications 11, no. 1 (2020): 1-11.
22. Andersson, Tom R., J. Scott Hosking, MarÃ­a PÃ©rez-Ortiz, Brooks Paige, Andrew Elliott, Chris Russell, Stephen Law et al. â€œSeasonal Arctic sea ice forecasting with probabilistic deep learning.â€ Nature communications 12, no. 1 (2021): 1-12.
23. Storchan, Victor, Svitlana Vyetrenko, and Tucker Balch. â€œMAS-GAN: Adversarial Calibration of Multi-Agent Market Simulators.â€ (2020).
24. De Raedt, Luc, Robin Manhaeve, Sebastijan Dumancic, Thomas Demeester, and Angelika Kimmig. â€œNeuro-symbolic=neural+ logical+ probabilistic.â€ In NeSyâ€™19&#64; IJCAI, the 14th International Workshop on Neural-Symbolic Learning and Reasoning. 2019.
25. Eyring, V., Bony, S., Meehl, G. A., Senior, C. A., Stevens, B., Stouffer, R. J., and Taylor, K. E.: Overview of the Coupled Model Intercomparison Project Phase 6 (CMIP6) experimental design and organization, Geosci. Model Dev., 9, 1937-1958, doi:10.5194/gmd-9-1937-2016, 2016.
26. Swingedouw, Didier, Chinwe Ifejika Speranza, Annett Bartsch, Gael Durand, Cedric Jamet, Gregory Beaugrand, and Alessandra Conversi. â€œEarly warning from space for a few key tipping points in physical, biological, and social-ecological systems.â€ Surveys in geophysics 41, no. 6 (2020): 1237-1284.
27. Reichstein, Markus, Gustau Camps-Valls, Bjorn Stevens, Martin Jung, Joachim Denzler, and Nuno Carvalhais. â€œDeep learning and process understanding for data-driven Earth system science.â€ Nature 566, no. 7743 (2019): 195-204.
28. Sleeman, Jennifer, Ivanka Stajner, Christoph Keller, Milton Halem, Christopher Hamer, Raffaele Montuoro, and Barry Baker. â€œThe Integration of Artificial Intelligence for Improved Operational Air Quality Forecasting.â€ In AGU Fall Meeting 2021. 2021.
29. Bellomo, K., Angeloni, M., Corti, S. et al. Future climate change shaped by inter-model differences in Atlantic meridional overturning circulation response. Nat Commun 12, 3659 (2021). https://doi.org/10.1038/s41467-021-24015-w
30. Sgubin, G., Swingedouw, D., Drijfhout, S. et al. Abrupt cooling over the North Atlantic in modern climate models. Nat Commun 8, 14375
(2017). https://doi.org/10.1038/ncomms14375
31. Swingedouw, D., Bily, A., Esquerdo, C., Borchert, L. F., Sgubin, G., Mignot, J., &amp; Menary, M. (2021). On the risk of abrupt changes in the North Atlantic subpolar gyre in CMIP6 models. Annals of the New York Academy of Sciences, 1504(1), 187-201. https://doi.org/10.1111/nyas.14659
32. Mao, Jiayuan, Chuang Gan, Pushmeet Kohli, Joshua B. Tenenbaum, and Jiajun Wu. â€œThe neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision.â€ arXiv preprint arXiv:1904.12584 (2019).</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="milestone7_report.html" class="btn btn-neutral float-left" title="Milestone 7 Progress Report" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="milestone9_report.html" class="btn btn-neutral float-right" title="Milestone 9 Progress Report" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, The Johns Hopkins University Applied Physics Laboratory LLC. All rights reserved..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>