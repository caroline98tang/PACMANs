<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Milestone 4 Progress Report &mdash; PACMANS  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Milestone 5 Progress Report" href="milestone5_report.html" />
    <link rel="prev" title="Milestone 3 Progress Report" href="milestone3_report.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> PACMANS
            <img src="_static/pacman_logo_v1.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="summary.html">Project Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone1_report.html">Milestone 1 Progress Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone2_report.html">Milestone 2 Progress Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone3_report.html">Milestone 3 Progress Report</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Milestone 4 Progress Report</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">1      Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#goals-and-impact">2      Goals and Impact</a></li>
<li class="toctree-l2"><a class="reference internal" href="#key-findings">3      Key Findings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#task-3-3-surrogate-learning">4      Task 3.3 – Surrogate Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#task-4-3-ai-simulation">5      Task 4.3 – AI Simulation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#gan-experiments">GAN Experiments</a></li>
<li class="toctree-l3"><a class="reference internal" href="#neuro-symbolic-learning">Neuro-Symbolic Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#causality">Causality</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#summary">6 Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="milestone5_report.html">Milestone 5 Progress Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone6_report.html">Milestone 6 Progress Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone7_report.html">Milestone 7 Progress Report</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyBAMOCS:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="pyBAMOCS_intro.html">Introduction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Help &amp; Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="people.html">Our Team</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PACMANS</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Milestone 4 Progress Report</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/milestone4_report.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="milestone-4-progress-report">
<h1>Milestone 4 Progress Report<a class="headerlink" href="#milestone-4-progress-report" title="Permalink to this heading"></a></h1>
<p><strong>PACMANS TEAM:</strong>
• Jennifer Sleeman (JHU APL) PI
• Anand Gnanadesikan (JHU) Co-PI
• Yannis Kevrekidis (JHU) Co-PI
• Jay Brett (JHU APL)
• David Chung (JHU APL)
• Chace Ashcraft (JHU APL)
• Thomas Haine (JHU)
• Marie-Aude Pradal (JHU)
• Renske Gelderloos (JHU)
• Caroline Tang (DUKE)
• Anshu Saksena (JHU APL)
• Larry White (JHU APL)
• Marisa Hughes (JHU APL)</p>
<section id="overview">
<h2>1      Overview<a class="headerlink" href="#overview" title="Permalink to this heading"></a></h2>
<blockquote>
<div><p>This technical report covers the period of April 2022 through May
13, 2022. The report documents the achievement of the milestone associated with Month 5 of the JHU/APL-led PACMAN team’s statement of work. The delivery for this milestone is this report which highlights
progress made for the AI surrogate modeling and the AI simulation research.</p>
<div class="line-block">
<div class="line">• This report includes:</div>
<div class="line">• New architectures</div>
<div class="line">• Experimental definitions</div>
<div class="line">• Findings based on experimental results</div>
<div class="line">• Next steps</div>
</div>
</div></blockquote>
</section>
<section id="goals-and-impact">
<h2>2      Goals and Impact<a class="headerlink" href="#goals-and-impact" title="Permalink to this heading"></a></h2>
<dl class="simple">
<dt>Goals for this milestone included:</dt><dd><ul class="simple">
<li><p>Obtain the first set of experimental results for the AI surrogate modeling based on testing the formalizations described in Milestone 3</p></li>
<li><p>Perform early experimentation of a baseline GAN for a subset of explorations and what-if questions</p></li>
<li><p>Show feasibility of the causal model</p></li>
<li><p>Obtain baseline symbolic language experimental results</p></li>
</ul>
</dd>
</dl>
</section>
<section id="key-findings">
<h2>3      Key Findings<a class="headerlink" href="#key-findings" title="Permalink to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><dl class="simple">
<dt>Surrogate Learning (Task 3.3)</dt><dd><ul>
<li><p>Completed the first set of bifurcation diagrams for the box model equations</p></li>
<li><dl class="simple">
<dt>Discovered a new type of tipping point in the Box model using the non-dimensionalized equations</dt><dd><ul>
<li><p>In Gnanadesikan 2018 paper a fold bifurcation was assumed, we discovered subcritical Hopf bifurcation also exists for the reverse transition</p></li>
<li><p><strong>Plan to publish these findings – this represents a new insight into potential AMOC behavior</strong></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>AI simulation (Task 4.3)</dt><dd><ul>
<li><dl class="simple">
<dt>Completed first set of multi-agent generator GAN experiments using the box model data</dt><dd><ul>
<li><p><strong>Generators show a positive tendency towards AMOC collapse</strong></p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Setup a baseline neuro-symbolic experiment using rules-based model with a set of questions which correlate with the box model Gnanadesikan 2018 experiments</p></li>
<li><dl class="simple">
<dt>Developed a first approach for bi-directional translation between the neuro-symbolic language and the GAN perturbations</dt><dd><ul>
<li><p><strong>If successful, this model will show how a GAN’s perturbations of symbols can be translated to “purely generative” natural language questions</strong></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>To address questions around AMOC slowing vs. complete shut-off and recovery from AMOC, we are exploring causality at the model level</dt><dd><ul>
<li><p><strong>we expect to address these two areas with a probabilistic causal model</strong></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
</section>
<section id="task-3-3-surrogate-learning">
<h2>4      Task 3.3 – Surrogate Learning<a class="headerlink" href="#task-3-3-surrogate-learning" title="Permalink to this heading"></a></h2>
<blockquote>
<div><p><em>Subtask Description: Report on the first set of experimental results
based on testing the formalizations set forth in Milestone 3.</em></p>
<div class="line-block">
<div class="line">Accomplishments:</div>
<div class="line">• <strong>Major breakthrough</strong> in terms of bifurcation modeling</div>
</div>
<ul class="simple">
<li><p>We have been able to perform detailed bifurcation diagrams of the box model</p></li>
<li><p>This was enabled by a careful non-dimensionalization of the related equations, without which the accuracy of the numerical computations would be unsatisfactory</p></li>
<li><p>With the non-dimensionalized equations, the problem possesses not one but two tipping points (fold and Hopf bifurcations)</p></li>
</ul>
<p>With the non-dimensionalized equations, the problem possesses not one
but two tipping points (from the “upper” branch to the lower, but
also from the lower to the upper) as shown in Figures 1-2.</p>
<a class="reference internal image-reference" href="_images/image28.png"><img alt="_images/image28.png" src="_images/image28.png" style="width: 5.01806in; height: 3.7625in;" /></a>
<a class="reference internal image-reference" href="_images/image29.png"><img alt="_images/image29.png" src="_images/image29.png" style="width: 5.01805in; height: 3.7625in;" /></a>
<p><strong>Figures 1a-1b. Diagram of NH Overturning Mn (a) and Zoomed-In View
of the subcritical Hopf Bifurcation Point (b).</strong></p>
<p>Second view - the two tipping points are of different nature: one of
the two is the fold point bifurcation, but the second one is a
subcritical Hopf, highlighted in Figures 1-2. The Hopf at
TrFWn=0.0384 is subcritical.</p>
<p><a class="reference internal" href="_images/image30.png"><img alt="image31" src="_images/image30.png" style="width: 5.07639in; height: 3.87083in;" /></a> <a class="reference internal" href="_images/image31.png"><img alt="image32" src="_images/image31.png" style="width: 5.07639in; height: 3.87083in;" /></a></p>
<p><strong>Figures 2a-2b. Diagram of Low Latitude Depth D* (a) and Zoomed-In
View of the Hopf Bifurcation Point (b).</strong></p>
<ul class="simple">
<li><p>The value where the limit cycle branch appears to become  vertical (an infinite period, homoclinic orbit) is 0.0375.</p></li>
<li><p>The subcritical Hopf gives birth to an unstable limit cycle “backwards” in parameter space (that surrounds the exiting stable steady state).</p></li>
<li><p>This steady state loses stability at the Hopf bifurcation (red branch in Figures 1-2).</p></li>
<li><p>The escape (the “tipping”) arises when a stochastic trajectory wandering around the stable state manages to “cross” the unstable limit cycle and escape to either large oscillations or to a completely different lower circulation branch.</p></li>
</ul>
<p>Where the initial condition with D=1 (where D is the Low latitude
pycnocline depth) is attracted by the upper branch because there is
an early switch activation, so the sharp transition that we see is
given by the upper limit point LP. While for D=4 we observe the sharp
transition close to the subcritical Hopf (the solution loses
stability at the exact Hopf point, because the initial condition may
start outside the unstable limit cycle).</p>
<p><a class="reference internal" href="_images/image32.png"><img alt="image35" src="_images/image32.png" style="width: 5.08056in; height: 3.80972in;" /></a> <a class="reference internal" href="_images/image33.png"><img alt="image36" src="_images/image33.png" style="width: 5.08055in; height: 3.80972in;" /></a></p>
<p><strong>Figures 3a-3b. Temporal Bifurcation Diagram for Depth (a) and the
Limit Cycle Continuation (b).</strong></p>
</div></blockquote>
<dl class="simple">
<dt>Next Steps:</dt><dd><ul class="simple">
<li><p>We are working on a stochastic simulation close to the presented tipping points, to collect data towards a targeted surrogate model. This will allow us to efficiently and accurately estimate escape time distributions.</p></li>
<li><p>We will learn targeted effective stochastic DEs (one-dimensional at the LP tipping, two-dimensional at the Hopf tipping) and use them to estimate escape time statistics in both cases.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="task-4-3-ai-simulation">
<h2>5      Task 4.3 – AI Simulation<a class="headerlink" href="#task-4-3-ai-simulation" title="Permalink to this heading"></a></h2>
<blockquote>
<div><p><em>Subtask Description: Report on early experimentation of a baseline
GAN for a subset of explorations and what-if questions, including a
set of experiments that show feasibility of the causal model, and
baseline symbolic language experimental results.</em></p>
<div class="line-block">
<div class="line">Accomplishments:</div>
<div class="line">• Started conducting GAN experiments using the box model data •
Exploring behavior of multi-agent GAN loss function</div>
</div>
<div class="line-block">
<div class="line">• Exploring optimal number of generators</div>
<div class="line">• Developed architectures needed for a baseline neuro-symbolic
language that enables a translation from human-specific questions
to the GAN simulation, and from perturbed GAN runs to questions.</div>
</div>
<ul class="simple">
<li><p>Set up a baseline model that will be used for experimentation</p></li>
<li><p>Defined causality in terms of model behavior/time</p></li>
</ul>
</div></blockquote>
<section id="gan-experiments">
<h3>GAN Experiments<a class="headerlink" href="#gan-experiments" title="Permalink to this heading"></a></h3>
<blockquote>
<div><div class="line-block">
<div class="line">• Three experiments using the Box model simulation data</div>
<div class="line">• With a vector of 3 dimensions and perturbations of parameters</div>
</div>
<div class="line-block">
<div class="line">(bounded):
• Dlow0 (Thermocline depth of lower latitudes): [100.0, 400.0]
• Mek (Ekman flux from the southern ocean): [1.5e7, 3.5e7]
• Fwn (Fresh water flux (North)): [5.0e4, 1.55e6]</div>
</div>
<ul class="simple">
<li><p>Data was augmented for uniform sampling from a 3-D space</p></li>
<li><p>In addition to samples, generated 1,000 synthetic samples</p></li>
<li><p>Distribution of shutoff vs non-shutoff samples 743/413</p></li>
</ul>
<div class="line-block">
<div class="line">• Trained the GAN using equally-weighted generators</div>
<div class="line">• Shutoff classification cross-entropy loss functions</div>
<div class="line">• Ran for ~250 epochs</div>
<div class="line">• Ran experiments with n = to the number of generators where n ∈ [1,2,4]</div>
<div class="line">• Generated samples result in shutoffs/non-shutoffs</div>
</div>
</div></blockquote>
<ul class="simple">
<li><p>Discriminator performance in classifying runs as shut-off or not•</p></li>
<li><dl class="simple">
<dt>High F-measure scores indicate the discriminator was able to accuracy classify shut-off from non-shut-off runs for held-out test</dt><dd><p>set</p>
</dd>
</dl>
</li>
</ul>
<p><strong>Table 1. Precision, Recall, F-Measure scores for 1,2,4 generator GANs.</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 29%" />
<col style="width: 25%" />
<col style="width: 20%" />
<col style="width: 2%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p><strong>Precision</strong></p></th>
<th class="head"><p><strong>Recall</strong></p></th>
<th class="head"></th>
<th class="head"><p><strong>F-Measure</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>1 Generator</strong></p></td>
<td><p>1</p></td>
<td></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p><strong>2 Generators</strong></p></td>
<td><p>0.993</p></td>
<td></td>
<td><p>1</p></td>
<td><p>0.997</p></td>
</tr>
<tr class="row-even"><td><p><strong>4 Generators</strong></p></td>
<td><p>0.929</p></td>
<td></td>
<td><p>1</p></td>
<td><p>0.963</p></td>
</tr>
</tbody>
</table>
<p><strong>Small initial experiment- but very promising results from
discriminator in classifying runs</strong></p>
<blockquote>
<div><div class="line-block">
<div class="line">• After training the GAN, sampled 500 times</div>
<div class="line">• Generators tend to favor exploring areas of shut-offs</div>
</div>
<div class="line-block">
<div class="line">• Training data had some imbalance</div>
<div class="line">• Larger dataset would provide verification</div>
</div>
<p><strong>Table 2. For 1,2,4 generator GANs – Fraction of 500 samples that
resulted in a shut-off.</strong></p>
</div></blockquote>
<p><strong>Generator Idx</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 36%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"></th>
<th class="head"><p><strong>0</strong></p></th>
<th class="head"><p><strong>1</strong></p></th>
<th class="head"><p><strong>2</strong></p></th>
<th class="head"><p><strong>3</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Number of</strong></p></td>
<td><p><strong>1</strong></p></td>
<td><p>0.854</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p><strong>2</strong></p></td>
<td><p>0.992</p></td>
<td><p>0.998</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
</tr>
<tr class="row-even"><td><p><strong>Generators</strong></p></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p><strong>4</strong></p></td>
<td><p>0.982</p></td>
<td><p>0.986</p></td>
<td><p>0.972</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<p><strong>The trained generators are successfully generating a latent space of
shut-offs</strong></p>
<ul>
<li><p>Early GAN results show interesting results regarding M_n and shut-off</p>
<blockquote>
<div><p>behavior. More experimentation is underway to explore this further.</p>
</div></blockquote>
</li>
</ul>
<p><strong>Figure 4a-c. GAN generated shut-offs for 1 generator (a), 2 generators
(b), and 4 generators (c).</strong><a class="reference internal" href="_images/image34.png"><img alt="image42" src="_images/image34.png" style="width: 4.61944in; height: 4.61944in;" /></a><a class="reference internal" href="_images/image35.png"><img alt="image43" src="_images/image35.png" style="width: 4.61944in; height: 4.61944in;" /></a><a class="reference internal" href="_images/image36.png"><img alt="image44" src="_images/image36.png" style="width: 4.61944in; height: 4.61944in;" /></a></p>
<dl>
<dt>Observations:</dt><dd><blockquote>
<div><ul class="simple">
<li><p>The n=1 generator case produces the greatest fraction of
configurations that are non-shutoff states. This could be attributed to the GAN having</p></li>
</ul>
<p>more synthetic samples to learn from (i.e. n=2 and n=4 training loops
versus n=1 training loop per epoch).</p>
<ul class="simple">
<li><p>For this particular scenario (i.e. 3 perturbed features w/ fixed</p></li>
</ul>
<p>bounds), it appears that n=1 generator is enough to roughly capture
the shutoff configurations in this feature space. However, it’s still
to be determined how the generators will perform when allowed to
perturb more than 3 features.</p>
</div></blockquote>
<ul>
<li><p>For Fwn the n=1 generator GAN learns a bi-modal sampling
distribution with modes centered at approx.. 0.65e6 and 1.3e6.</p>
<ul class="simple">
<li><p>When n=2 or n=4, generators learns a left-skewed uni-modal sampling distribution with mode centered at approx.. 1.3e6.</p></li>
</ul>
<p><strong>Figure 5a-c. Histograms showing distribution of generated shut-offs
for 1 generator (a), 2 generators (b), and 4 generators
(c).</strong><a class="reference internal" href="_images/image37.png"><img alt="image47" src="_images/image37.png" style="width: 4in; height: 4in;" /></a><a class="reference internal" href="_images/image38.png"><img alt="image48" src="_images/image38.png" style="width: 4in; height: 4in;" /></a><a class="reference internal" href="_images/image39.png"><img alt="image49" src="_images/image39.png" style="width: 4in; height: 4in;" /></a></p>
</li>
</ul>
</dd>
<dt>Observations:</dt><dd><ul class="simple">
<li><p>The mode at 0.65e6 has a large cluster of non-shutoff states,</p></li>
</ul>
<blockquote>
<div><p>while the mode at 1.3e6 appears to be a cluster for a shutoff state. This finding
also coincides with the larger fraction of non-shutoff states generated
by the n=1 GAN vs. n=2 and n=4 GANs.</p>
<blockquote>
<div><ul class="simple">
<li><p>Discriminators incorrectly classify a larger fraction of real samples as synthetic as the number of generators increases.</p></li>
</ul>
</div></blockquote>
</div></blockquote>
</dd>
</dl>
</section>
<section id="neuro-symbolic-learning">
<h3>Neuro-Symbolic Learning<a class="headerlink" href="#neuro-symbolic-learning" title="Permalink to this heading"></a></h3>
<blockquote>
<div><div class="line-block">
<div class="line">Neuro-symbolic architecture has been defined in terms of levels ofrepresentation:</div>
</div>
<ul class="simple">
<li><p>Text level – climate modeler asks questions</p></li>
<li><p>Symbolic level – “programs” generated from natural language</p></li>
<li><p>Vector level – GAN works at vector-level perturbing parameters</p></li>
</ul>
<div class="line-block">
<div class="line">• Model level – Surrogate receives input in terms of initial conditions and parameters to run model</div>
</div>
<a class="reference internal image-reference" href="_images/image40.png"><img alt="_images/image40.png" src="_images/image40.png" style="width: 6.36805in; height: 3.54167in;" /></a>
<p><strong>Figure 6. Levels of Representation from Natural Language to Model
runs.</strong></p>
<ul class="simple">
<li><p>In training mode: GAN explores space through perturbations</p></li>
<li><p>Perturbations are translated into “programs”</p></li>
<li><p>“Programs” are translated into natural language</p></li>
<li><p>In trained mode: Questions can be asked of the model</p></li>
<li><p>Questions are translated into ‘programs’</p></li>
<li><p>‘Programs’ are used to find answers using latent space</p></li>
</ul>
</div></blockquote>
<table class="docutils align-default">
<colgroup>
<col style="width: 8%" />
<col style="width: 92%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><ol class="loweralpha simple">
<li></li>
</ol>
</td>
<td><a class="reference internal image-reference" href="_images/image43.png"><img alt="_images/image43.png" src="_images/image43.png" style="width: 5.01111in; height: 1.95972in;" /></a>
</td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 8%" />
<col style="width: 92%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><ol class="loweralpha simple" start="2">
<li></li>
</ol>
</td>
<td><a class="reference internal image-reference" href="_images/image44.png"><img alt="_images/image44.png" src="_images/image44.png" style="width: 5.01111in; height: 1.95972in;" /></a>
</td>
</tr>
</tbody>
</table>
<blockquote>
<div><p><strong>Figure 9a-b. Question Template for Version 1 of Neuro-symbolic
language (a) and Example Question Using this Template
(b).</strong></p>
<blockquote>
<div><ul class="simple">
<li><p><strong>Have currently developed a rule-based method that generates encodings of questions as “programs”</strong></p></li>
<li><p>Based on a defined Domain Specific Language (DSL)</p></li>
<li><p>Will be used as a baseline for evaluating deep learning methods</p></li>
<li><p>Built an automatic question generator for questions following the form in Figure 9a.</p></li>
<li><p>Experimenting with a sequence-to-sequence autoencoder to encode questions, and decode into vector input for a GAN</p></li>
<li><p>Based on a sequence-to-sequence machine translation</p></li>
<li><p>Includes an encoder, encoder vector, and decoder</p></li>
<li><p>Encoder has LSTM units stacked, each accepting an element from the question</p></li>
<li><p>Encoder vector captures information across the question</p></li>
<li><p>Decoder has a stack of LSTMs each predicting an output</p></li>
<li><p>This model supports varying length input/output though we are starting with a fixed length and using padding</p></li>
</ul>
</div></blockquote>
<a class="reference internal image-reference" href="_images/image45.png"><img alt="_images/image45.png" src="_images/image45.png" style="width: 4.35694in; height: 2.0375in;" /></a>
<p><strong>Figure 10. Seq-to-seq Deep Autoencoder for Learning Translations
Between Text and Programs, and Programs and Vectors.</strong></p>
<div class="line-block">
<div class="line"><a class="reference internal" href="_images/image46.png"><img alt="image58" src="_images/image46.png" style="width: 7.55417in; height: 3.94028in;" /></a></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p>Also, beginning to experiment with the workflow shown in Figure 11</p></li>
<li><p>Starting with experiments that focus on question to program translation• A model that learns a fixed sized embedding of the question</p></li>
<li><p>Translatable to programs and readable text</p></li>
<li><p>Based on Neuro-Symbolic Concept Learner</p></li>
</ul>
</div></blockquote>
<p><strong>Figure 11. Novel Neuro-Symbolic Architecture for Translating
Questions to Programs based on Neuro-Symbolic Concept Learner
(NS-CL).</strong></p>
<ul class="simple">
<li><dl class="simple">
<dt>Next Steps:</dt><dd><ul>
<li><p>Measure performance of the following translations:</p></li>
<li><p>Questions to programs **</p></li>
<li><p>Vectors to programs</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<a class="reference internal image-reference" href="_images/image47.png"><img alt="_images/image47.png" src="_images/image47.png" style="width: 8.60833in; height: 2.12083in;" /></a>
<p><strong>Figure 12. Visualizing Translations Between Levels – Questions
to/from Symbolic Programs (top) and Symbolic Programs to/from Vectors
(bottom).</strong></p>
</div></blockquote>
</section>
<section id="causality">
<h3>Causality<a class="headerlink" href="#causality" title="Permalink to this heading"></a></h3>
<p><strong>New Insights</strong></p>
<blockquote>
<div><p>To address two outstanding issues:</p>
<p>1.) AMOC slowing as shown in Figure 13 and inferring likelihood of shutoff, and</p>
<p>2.) Learning how to recover from an AMOC shutoff</p>
<ul class="simple">
<li><p>Developing causal inference based on temporal evolution of system state</p></li>
<li><p>Working on a model to learn relevant causal structures that are occurring as a result of dynamics included in surrogate model<a class="reference internal" href="_images/image48.png"><img alt="image61" src="_images/image48.png" style="width: 4.29861in; height: 3.59425in;" /></a></p></li>
<li><p>Causal model will capture intermediate states along the way to AMOC shutoffs, focusing on particular states that lie at causal forks in the road of the system’s temporal evolution and that are most</p></li>
</ul>
<p>relevant to whether there will be a shutoff or not</p>
<ul class="simple">
<li><p>Will be used to assign probabilities to potential outcomes</p></li>
</ul>
<p><strong>Figure 13. CESM-2 Model Runs that show weakening of the AMOC.</strong></p>
</div></blockquote>
</section>
</section>
<section id="summary">
<h2>6 Summary<a class="headerlink" href="#summary" title="Permalink to this heading"></a></h2>
<blockquote>
<div><p>In summary, we have shared results from our initial experimentation
related to the surrogate modeling and the AI simulation, specifically
related to the GAN and the neuro-symbolic language.</p>
<p>With Milestone 5, we will continue to push forward with building
large GCM calibrated data sets and extensions to the box model.</p>
<p><a class="reference internal" href="_images/image49.png"><img alt="image63" src="_images/image49.png" style="width: 5.49444in; height: 4.08056in;" /></a></p>
</div></blockquote>
<p><strong>Approved for public release; distribution is unlimited. This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Agreement No. HR00112290032.</strong></p>
<p><strong>Citations</strong></p>
<blockquote>
<div><p>1. Boers, Niklas. “Observation-based early-warning signals for a
collapse of the Atlantic Meridional Overturning Circulation.” Nature
Climate Change 11, no. 8 (2021): 680-688.</p>
<p>2. Gnanadesikan, A., A simple model for the structure of the oceanic
pycnocline, Science., 283:2077-2079, (1999).</p>
<div class="line-block">
<div class="line">3. Forget, G., J.-M. Campin, P. Heimbach, C. N. Hill, R. M. Ponte,
C. Wunsch, ECCO version 4: An integrated framework for non-linear
inverse modeling and global ocean state estimation. Geosci. Model
Dev. 8, 3071–3104 (2015)</div>
<div class="line">4. Gnanadesikan, A., R. Kelson and M. Sten, Flux correction and
overturning stability: Insights from a dynamical box model, J.
Climate, 31, 9335-9350, <a class="reference external" href="https://doi.org/10.1175/JCLI-D-18-0388.1">https://doi.org/10.1175/JCLI-D-18-0388.1</a>,
(2018).</div>
</div>
<p>5. Kaufhold, John Patrick, and Jennifer Alexander Sleeman. “Systems
and methods for deep model translation generation.” U.S. Patent No.
10,504,004. 10 Dec. 2019.</p>
<p>6. Garcez, Artur d’Avila, and Luis C. Lamb. “Neurosymbolic AI: the
3rd Wave.” arXiv preprint arXiv:2012.05876 (2020).</p>
<p>7. Stommel, H. Thermohaline convection with two stable regimes of
flow. Tellus 13, 224–230 (1961).</p>
<p>8. Karniadakis, George Em, Ioannis G. Kevrekidis, Lu Lu, Paris
Perdikaris, Sifan Wang, and Liu Yang. “Physics-informed machine
learning.” Nature Reviews Physics 3, no. 6 (2021): 422-440.</p>
<p>9. Sleeman, Jennifer, Milton Halem, Zhifeng Yang, Vanessa Caicedo,
Belay Demoz, and Ruben Delgado. “A Deep Machine Learning Approach for
LIDAR Based Boundary Layer Height Detection.” In IGARSS 2020-2020
IEEE International Geoscience and Remote Sensing Symposium, pp.
3676-3679. IEEE, 2020.</p>
<p>10. Patel, Kinjal, Jennifer Sleeman, and Milton Halem. “Physics-aware
deep edge detection network.” In Remote Sensing of Clouds and the
Atmosphere XXVI, vol. 11859, pp. 32-38. SPIE, 2021.</p>
<p>11.Brulé, Joshua. “A causation coefficient and taxonomy of
correlation/causation relationships.” arXiv preprint arXiv:1708.05069
(2017).</p>
<p>12. Rasp, Stephan, Michael S. Pritchard, and Pierre Gentine. “Deep
learning to represent subgrid processes in climate models.”
Proceedings of the National Academy of Sciences 115, no. 39 (2018):
9684-9689.</p>
<p>13. Bolton, Thomas, and Laure Zanna. “Applications of deep learning
to ocean data inference and subgrid parameterization.” Journal of
Advances in Modeling Earth Systems 11, no. 1 (2019): 376-399.</p>
<p>14. Kurth, Thorsten, Sean Treichler, Joshua Romero, Mayur Mudigonda,
Nathan Luehr, Everett Phillips, Ankur Mahesh et al. “Exascale deep
learning for climate analytics.” In SC18: International Conference
for High Performance Computing, Networking, Storage and Analysis, pp.
649-660. IEEE, 2018.</p>
</div></blockquote>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="milestone3_report.html" class="btn btn-neutral float-left" title="Milestone 3 Progress Report" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="milestone5_report.html" class="btn btn-neutral float-right" title="Milestone 5 Progress Report" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, The Johns Hopkins University Applied Physics Laboratory LLC. All rights reserved..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>